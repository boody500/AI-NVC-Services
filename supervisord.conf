[supervisord]
nodaemon=true
user=root


[program:web]
stdout_logfile_maxbytes=0
stderr_logfile_maxbytes=0
command=gunicorn app:app --bind 0.0.0.0:8000 --workers 2 --threads 2 --timeout 600
stdout_logfile=/dev/stdout
stderr_logfile=/dev/stderr
redirect_stderr=true


[program:worker1]
stdout_logfile_maxbytes=0
stderr_logfile_maxbytes=0
; Run Celery in "solo" or "threads" pool to avoid forking heavy ML models
; Limit concurrency to prevent multiple big jobs eating memory
command=celery -A tasks.celery worker --loglevel=info --concurrency=2 -P threads --prefetch-multiplier=2 -n worker1
stdout_logfile=/dev/stdout
stderr_logfile=/dev/stderr




